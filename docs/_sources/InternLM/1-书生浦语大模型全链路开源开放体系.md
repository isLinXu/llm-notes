# 1-书生浦语大模型全链路开源开放体系

---

 1.大模型为发展通用人工智能的重要途经

- 专用模型：针对特定任务解决特定问题
- 通用大模型：一个模型对应多模态多任务

书生·浦语大模型系列

- 轻量级：InternLM-7B

  - 70亿模型参数

  - 1000亿训练token数据

  - 长语境能力，支持8K语境窗口长度

  - 通用工具调用能力，多种工具调用模板

- 中量级：InternLM-20B
  - 200亿模型参数，在模型能力与推理代价间取得平衡    
  - 采用深而窄的结果，降低推理计算量但提高推理能力
  - 4K训练语境长度，推理时可外推至16K
- 重量级：1230亿模型参数，强大的性能
    - 极强推理能力、全面的知识覆盖面、超级理解能力与对话能力
    - 准确的API调用能力，可实现各类Agent

2.InterLM大模型开源历程

![image](https://github.com/isLinXu/llm-notes/assets/59380685/a37610b9-7b69-4fc7-ac57-1f633cd6d672)


3.InterLM-20B性能遥遥领先

![image](https://github.com/isLinXu/llm-notes/assets/59380685/6963efd4-b744-41d3-9c3e-f3582162e90a)


4.模型应用：智能客服、个人助手、行业应用

![image](https://github.com/isLinXu/llm-notes/assets/59380685/35c8e8ed-7942-4e9c-85ec-2becf1463e38)


5.书生浦语全链条开放体系

![image](https://github.com/isLinXu/llm-notes/assets/59380685/783f2942-5ca2-4550-b5f2-60ef4f1b90d5)

- 数据：2TB数据，涵盖多种模态与任务
- 预训练：InternLM-Train
- 并行训练，极致优化速度达到3600 Tokens/sec/gpu
- 微调：XTuner
  - 支持全参数微调
  - 支持LoRA等低成本微调
- 部署：LMDeploy
  - 全链路部署，性能领先
  - 每秒生成2000+tokens     
- 评测：OpenCompass
  - 全方位评测，性能可复现80套评测集，40万道题目
- 应用：
  - Legent（轻量级智能体框架）：搭建简单的智能体
  - AgentLego：支持多种智能体，支持代码解释器等多种工具

6.数据

- 书生万卷（文本、图像文本、视频）

![image](https://github.com/isLinXu/llm-notes/assets/59380685/930e7b51-1ed3-4caf-ad97-0401b953a5c9)

- 文本数据：50亿个文档，数据量超1TB
- 图像-文本数据集：超2200万个文件，数据量超140GB
- 视频数据：超1000个文件，数据量超900GB
- 特点：
  - 多模态融合：万卷包含文本、图像和视频等多模态数据，涵盖科技、文学、媒体、教育和法律等多个领域。该数据集对模型的知识内容、逻辑推理和泛化能力的提升有显著提升。
  - 精细化处理：万卷经过语言筛选、文本提取、格式标准化、数据过滤和清洗（基于规则和模型）、多尺度去重和数据质量评估等精细数据处理环节，能够很好地适应后续模型训练的要求
  - 价值观对齐：在万卷的构建过程中，研究人员注重将数据内容与主流中国价值观进行对齐，并通过算法和人工评估的结合提高语料库的纯净度。

 - OpenDataLab(提供智能标注工具)

7.预训练:InterLM-Train(全面)

![image](https://github.com/isLinXu/llm-notes/assets/59380685/2952175a-5f6b-4022-b175-e48f2cbf9406)

- 高可扩展：支持从8卡到千卡训练，千卡加速效率达92%。
- 极致性能优化：Hybrid Zero独特技术+极致优化，加速50%
- 兼容主流：无缝接入HuggingFace等技术生态，支持各类轻量化技术
- 开箱即用：支持多种规格语言模型，修改配置即可训练

8.微调：XTuner(高兼容)

![image](https://github.com/isLinXu/llm-notes/assets/59380685/473af8fd-a5dc-410e-a0d2-9c6f5e0bfbb6)

- 增量续训
  - 使用场景：让基座模型学习到一些新知识，如某个垂类领域知识
  - 训练数据：文章、书籍、代码等
- 有监督微调
  - 使用场景：让模型学会理解和遵循各种指令，或者注入少量领域知识
  - 训练数据：高质量对话、问答数据

- 部分参数微调LoRA：固定已有参数，加入新参数进行微调。

![image](https://github.com/isLinXu/llm-notes/assets/59380685/2ea5e763-5b1f-4961-be0c-c00d135c65f5)

- 极致的显存优化8GB显卡（2080、4060）-7GB模型微调

9.测评：OpenCompass

![image](https://github.com/isLinXu/llm-notes/assets/59380685/428e7d31-54e8-472d-9da1-341bb8a11f62)


全球领先、全面体系

![image](https://github.com/isLinXu/llm-notes/assets/59380685/eaae2d8e-4487-4e8c-b7ac-99230f1fe681)

平台架构

![image](https://github.com/isLinXu/llm-notes/assets/59380685/bdada714-9907-4080-8250-59b4444dcc63)

- 特点:丰富模型支持、丰富的API、分布式评测能力、便捷的数据集接口构建自己的数据集、快速迭代、用户遍布。

![image](https://github.com/isLinXu/llm-notes/assets/59380685/1ae57f93-9744-4d21-889d-c121c81fcac1)

10.部署

- 大语言模型特点
  - 内存开销巨大
    - 庞大的参数量
    - 采用自回归生成token,需要缓存k/v
  - 动态Shaps
    - 请求数不固定
    - token逐个生成，且数量不定
  - 模型结构相对简单
    - transformer结构，大部分是decoder-only
  
- 技术挑战
  - 设备
    - 低存储设备：消费级显卡、移动端等如何部署？
  - 推理
    - 如何加速token的生成速度
    - 如何解决动态shape，让推理可以不间断
    - 如何有效管理和利用内存     
  
- 服务

  - 提升系统整体吞吐量

  - 降低请求的平均响应时间

- 部署方案
    - 技术点
      - 模型并行
      - 低比特量化
      - Atterntion优化
      - 计算和访存优化
      - Continuous Batching

- 挑战

为解决上述挑战，开源LMDeploy

![image](https://github.com/isLinXu/llm-notes/assets/59380685/5df7709e-eff5-464b-9c90-cafbfef24dc8)

- 推理性能遥遥领先

![image](https://github.com/isLinXu/llm-notes/assets/59380685/b159f4c2-863c-4017-9446-ee478ae16666)


11.智能体应用

- 大模型驱动智能体
- 智能体以大模型为核心，进行调用、规划、推理和执行。

![image](https://github.com/isLinXu/llm-notes/assets/59380685/2bcf1946-5ebe-4004-8645-0027c174ba03)

- 轻量级智能体框架Lagent

![image](https://github.com/isLinXu/llm-notes/assets/59380685/6f88eab9-7105-42a8-b6ae-0624ae309b05)

例子

![image](https://github.com/isLinXu/llm-notes/assets/59380685/108c60c8-1fd2-4337-92aa-dc98c6073ac9)


- 多模态智能体工具箱AgentLego

![image](https://github.com/isLinXu/llm-notes/assets/59380685/fa8ace9f-3614-4eeb-bff1-2e488b1550c1)

多模态智能体工具箱AgentLego

- 丰富的工具集合，尤其是提供了大量视觉、多模态相关领域的前沿算法功能
- 支持多个主流智能体系统，如LangChain,Transformers Agent，Lagent等
- 灵活的多模态工具调用接口，可以轻松支持各类输入输出格式的工具函数
- 一键式远程工具部署，轻松使用和调试大模型智能体
  
